{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khanh\\Anaconda3\\envs\\py35\\lib\\site-packages\\matplotlib\\cbook.py:136: MatplotlibDeprecationWarning: The finance module has been deprecated in mpl 2.0 and will be removed in mpl 2.2. Please use the module mpl_finance instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from matplotlib import style\n",
    "import yahoo_finance as yahoo\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.finance import candlestick_ohlc\n",
    "from IPython.display import display, Math, Latex\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>NDX</th>\n",
       "      <th>DJIA</th>\n",
       "      <th>SP500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date.1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>112.4375</td>\n",
       "      <td>116.0000</td>\n",
       "      <td>111.875</td>\n",
       "      <td>116.0000</td>\n",
       "      <td>10347700</td>\n",
       "      <td>87.761136</td>\n",
       "      <td>3790.550049</td>\n",
       "      <td>11357.509766</td>\n",
       "      <td>1455.219971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>114.0000</td>\n",
       "      <td>114.5000</td>\n",
       "      <td>110.875</td>\n",
       "      <td>112.0625</td>\n",
       "      <td>8227800</td>\n",
       "      <td>84.782175</td>\n",
       "      <td>3546.199951</td>\n",
       "      <td>10997.929688</td>\n",
       "      <td>1399.420044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>112.9375</td>\n",
       "      <td>119.7500</td>\n",
       "      <td>112.125</td>\n",
       "      <td>116.0000</td>\n",
       "      <td>12733200</td>\n",
       "      <td>87.761136</td>\n",
       "      <td>3507.310059</td>\n",
       "      <td>11122.650391</td>\n",
       "      <td>1402.109985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>118.0000</td>\n",
       "      <td>118.9375</td>\n",
       "      <td>113.500</td>\n",
       "      <td>114.0000</td>\n",
       "      <td>7971900</td>\n",
       "      <td>86.248013</td>\n",
       "      <td>3340.810059</td>\n",
       "      <td>11253.259766</td>\n",
       "      <td>1403.449951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>117.2500</td>\n",
       "      <td>117.9375</td>\n",
       "      <td>110.625</td>\n",
       "      <td>113.5000</td>\n",
       "      <td>11856700</td>\n",
       "      <td>85.869732</td>\n",
       "      <td>3529.600098</td>\n",
       "      <td>11522.559570</td>\n",
       "      <td>1441.469971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High      Low     Close    Volume  Adj Close  \\\n",
       "Date.1                                                                   \n",
       "2000-01-03  112.4375  116.0000  111.875  116.0000  10347700  87.761136   \n",
       "2000-01-04  114.0000  114.5000  110.875  112.0625   8227800  84.782175   \n",
       "2000-01-05  112.9375  119.7500  112.125  116.0000  12733200  87.761136   \n",
       "2000-01-06  118.0000  118.9375  113.500  114.0000   7971900  86.248013   \n",
       "2000-01-07  117.2500  117.9375  110.625  113.5000  11856700  85.869732   \n",
       "\n",
       "                    NDX          DJIA        SP500  \n",
       "Date.1                                              \n",
       "2000-01-03  3790.550049  11357.509766  1455.219971  \n",
       "2000-01-04  3546.199951  10997.929688  1399.420044  \n",
       "2000-01-05  3507.310059  11122.650391  1402.109985  \n",
       "2000-01-06  3340.810059  11253.259766  1403.449951  \n",
       "2000-01-07  3529.600098  11522.559570  1441.469971  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ibm/full_ibm.csv')\n",
    "df['Date.1'] = pd.to_datetime(df['Date.1'])\n",
    "df.set_index('Date.1', inplace=True)\n",
    "df.drop(['Date'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4240, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>NDX</th>\n",
       "      <th>DJIA</th>\n",
       "      <th>SP500</th>\n",
       "      <th>ewma_5</th>\n",
       "      <th>ewma_22</th>\n",
       "      <th>ewma_200</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Lower band</th>\n",
       "      <th>Upper band</th>\n",
       "      <th>Middle band</th>\n",
       "      <th>AO</th>\n",
       "      <th>AC</th>\n",
       "      <th>%R</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date.1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-02-25</th>\n",
       "      <td>109.8750</td>\n",
       "      <td>109.8750</td>\n",
       "      <td>104.9375</td>\n",
       "      <td>108.000</td>\n",
       "      <td>10312200</td>\n",
       "      <td>81.794653</td>\n",
       "      <td>4178.580078</td>\n",
       "      <td>9862.120117</td>\n",
       "      <td>1333.359985</td>\n",
       "      <td>110.379006</td>\n",
       "      <td>113.930717</td>\n",
       "      <td>115.468485</td>\n",
       "      <td>-1.540179</td>\n",
       "      <td>107.384880</td>\n",
       "      <td>120.746370</td>\n",
       "      <td>114.065625</td>\n",
       "      <td>-5.621691</td>\n",
       "      <td>-2.680221</td>\n",
       "      <td>66.650193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-28</th>\n",
       "      <td>104.6250</td>\n",
       "      <td>106.5000</td>\n",
       "      <td>103.9375</td>\n",
       "      <td>104.500</td>\n",
       "      <td>8479900</td>\n",
       "      <td>79.143900</td>\n",
       "      <td>4162.129883</td>\n",
       "      <td>10038.650391</td>\n",
       "      <td>1348.050049</td>\n",
       "      <td>108.419337</td>\n",
       "      <td>113.086350</td>\n",
       "      <td>115.130536</td>\n",
       "      <td>-2.041213</td>\n",
       "      <td>105.835213</td>\n",
       "      <td>121.589787</td>\n",
       "      <td>113.712500</td>\n",
       "      <td>-7.055147</td>\n",
       "      <td>-2.867868</td>\n",
       "      <td>68.812154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>105.5625</td>\n",
       "      <td>105.5625</td>\n",
       "      <td>100.9375</td>\n",
       "      <td>102.750</td>\n",
       "      <td>10484900</td>\n",
       "      <td>77.818524</td>\n",
       "      <td>4266.939941</td>\n",
       "      <td>10128.309570</td>\n",
       "      <td>1366.420044</td>\n",
       "      <td>106.529558</td>\n",
       "      <td>112.163277</td>\n",
       "      <td>114.756874</td>\n",
       "      <td>-2.543629</td>\n",
       "      <td>103.966489</td>\n",
       "      <td>122.508511</td>\n",
       "      <td>113.237500</td>\n",
       "      <td>-8.208456</td>\n",
       "      <td>-2.701728</td>\n",
       "      <td>69.893135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-01</th>\n",
       "      <td>102.0000</td>\n",
       "      <td>105.5000</td>\n",
       "      <td>100.0625</td>\n",
       "      <td>100.250</td>\n",
       "      <td>10807800</td>\n",
       "      <td>75.925129</td>\n",
       "      <td>4309.009766</td>\n",
       "      <td>10137.929688</td>\n",
       "      <td>1379.189941</td>\n",
       "      <td>104.436372</td>\n",
       "      <td>111.101869</td>\n",
       "      <td>114.327720</td>\n",
       "      <td>-3.099331</td>\n",
       "      <td>101.875492</td>\n",
       "      <td>123.624508</td>\n",
       "      <td>112.750000</td>\n",
       "      <td>-9.078860</td>\n",
       "      <td>-2.306103</td>\n",
       "      <td>71.437394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-02</th>\n",
       "      <td>100.5000</td>\n",
       "      <td>105.4375</td>\n",
       "      <td>99.5000</td>\n",
       "      <td>103.125</td>\n",
       "      <td>11192900</td>\n",
       "      <td>78.102533</td>\n",
       "      <td>4234.259766</td>\n",
       "      <td>10164.919922</td>\n",
       "      <td>1381.760010</td>\n",
       "      <td>103.999248</td>\n",
       "      <td>110.392690</td>\n",
       "      <td>114.002693</td>\n",
       "      <td>-3.277844</td>\n",
       "      <td>100.547640</td>\n",
       "      <td>123.914860</td>\n",
       "      <td>112.231250</td>\n",
       "      <td>-9.984559</td>\n",
       "      <td>-1.994816</td>\n",
       "      <td>69.661497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low    Close    Volume  Adj Close  \\\n",
       "Date.1                                                                   \n",
       "2000-02-25  109.8750  109.8750  104.9375  108.000  10312200  81.794653   \n",
       "2000-02-28  104.6250  106.5000  103.9375  104.500   8479900  79.143900   \n",
       "2000-02-29  105.5625  105.5625  100.9375  102.750  10484900  77.818524   \n",
       "2000-03-01  102.0000  105.5000  100.0625  100.250  10807800  75.925129   \n",
       "2000-03-02  100.5000  105.4375   99.5000  103.125  11192900  78.102533   \n",
       "\n",
       "                    NDX          DJIA        SP500      ewma_5     ewma_22  \\\n",
       "Date.1                                                                       \n",
       "2000-02-25  4178.580078   9862.120117  1333.359985  110.379006  113.930717   \n",
       "2000-02-28  4162.129883  10038.650391  1348.050049  108.419337  113.086350   \n",
       "2000-02-29  4266.939941  10128.309570  1366.420044  106.529558  112.163277   \n",
       "2000-03-01  4309.009766  10137.929688  1379.189941  104.436372  111.101869   \n",
       "2000-03-02  4234.259766  10164.919922  1381.760010  103.999248  110.392690   \n",
       "\n",
       "              ewma_200      MACD  Lower band  Upper band  Middle band  \\\n",
       "Date.1                                                                  \n",
       "2000-02-25  115.468485 -1.540179  107.384880  120.746370   114.065625   \n",
       "2000-02-28  115.130536 -2.041213  105.835213  121.589787   113.712500   \n",
       "2000-02-29  114.756874 -2.543629  103.966489  122.508511   113.237500   \n",
       "2000-03-01  114.327720 -3.099331  101.875492  123.624508   112.750000   \n",
       "2000-03-02  114.002693 -3.277844  100.547640  123.914860   112.231250   \n",
       "\n",
       "                  AO        AC         %R  \n",
       "Date.1                                     \n",
       "2000-02-25 -5.621691 -2.680221  66.650193  \n",
       "2000-02-28 -7.055147 -2.867868  68.812154  \n",
       "2000-02-29 -8.208456 -2.701728  69.893135  \n",
       "2000-03-01 -9.078860 -2.306103  71.437394  \n",
       "2000-03-02 -9.984559 -1.994816  69.661497  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_technical_indicator(data):\n",
    "    data['ewma_5'] = data['Close'].ewm(span=5).mean()\n",
    "    data['ewma_22'] = data['Close'].ewm(span=22).mean()\n",
    "    data['ewma_200'] = data['Close'].ewm(span=200).mean()\n",
    "    data['MACD'] = data['Close'].ewm(span=12).mean() - data['Close'].ewm(span=26).mean()\n",
    "    data['Lower band'] = data['Close'].rolling(window=20).mean() - 2*data['Close'].rolling(window=20).std()\n",
    "    data['Upper band'] = data['Close'].rolling(window=20).mean() + 2*data['Close'].rolling(window=20).std()\n",
    "    data['Middle band'] = data['Close'].rolling(window=20).mean()\n",
    "    data['AO'] = ((data['High'] + data['Low'])/2).rolling(window=5).mean() - ((data['High'] + data['Low'])/2).rolling(window=34).mean()\n",
    "    data['AC'] =  data['AO'] - data['AO'].rolling(window=5).mean()\n",
    "    data['%R'] = (data['High'].max() - data['Close'])*100/(data['High'].max()-data['Low'].min())\n",
    "    \n",
    "    return data.dropna(axis=0, how='any')\n",
    "   \n",
    "df = calculate_technical_indicator(df)\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## params\n",
    "# n_layers = 2 # Number of LSTM cells for multi LSTM cells\n",
    "temporal_windows = 30\n",
    "n_features = df.shape[1]\n",
    "hidden_size = 15 # lstm weight size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4210, 30, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_rnn_data(data, temporal_windows):\n",
    "    x = np.zeros((data.shape[0]-temporal_windows, temporal_windows, data.shape[1]))\n",
    "    data_array = data.as_matrix()\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i,:,:] = data_array[i:temporal_windows+i,:]\n",
    "    return x\n",
    "df_rnn = prepare_rnn_data(df, temporal_windows)\n",
    "df_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_target_array(data, horizons):\n",
    "    \n",
    "    l = np.zeros((data.shape[0] + horizons - 1, 1))\n",
    "    for i in range(data.shape[0]):\n",
    "        l[i] = (np.mean([data[i-j, k] for j, k in zip(range(horizons), range(horizons)) if (i >= j)]))\n",
    "    for i in range(horizons-1):\n",
    "        l[data.shape[0] + i] = data[-1,i+1]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "horizons = 5\n",
    "def prepare_data_target(data, horizons):\n",
    "    cols = data.columns\n",
    "    l = []\n",
    "    for h in range(horizons):\n",
    "        shift = data.shift(periods=-h, axis=0)\n",
    "        shift.columns = [(cols[i] + '_{}'.format(h+1)) for i in range(len(cols))]\n",
    "        l.append(shift)\n",
    "    output = pd.concat(l, axis=1)\n",
    "    output.dropna(axis=0, how='any', inplace=True)\n",
    "    return output\n",
    "df_target = prepare_data_target(df[['Close']], horizons)\n",
    "df_target = df_target.loc[df.index[temporal_windows:]]\n",
    "df_target.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_1</th>\n",
       "      <th>Close_2</th>\n",
       "      <th>Close_3</th>\n",
       "      <th>Close_4</th>\n",
       "      <th>Close_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date.1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-19</th>\n",
       "      <td>166.679993</td>\n",
       "      <td>167.600006</td>\n",
       "      <td>167.330002</td>\n",
       "      <td>167.059998</td>\n",
       "      <td>166.710007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-20</th>\n",
       "      <td>167.600006</td>\n",
       "      <td>167.330002</td>\n",
       "      <td>167.059998</td>\n",
       "      <td>166.710007</td>\n",
       "      <td>167.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-21</th>\n",
       "      <td>167.330002</td>\n",
       "      <td>167.059998</td>\n",
       "      <td>166.710007</td>\n",
       "      <td>167.139999</td>\n",
       "      <td>166.190002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>167.059998</td>\n",
       "      <td>166.710007</td>\n",
       "      <td>167.139999</td>\n",
       "      <td>166.190002</td>\n",
       "      <td>166.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>166.710007</td>\n",
       "      <td>167.139999</td>\n",
       "      <td>166.190002</td>\n",
       "      <td>166.600006</td>\n",
       "      <td>165.990005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close_1     Close_2     Close_3     Close_4     Close_5\n",
       "Date.1                                                                \n",
       "2016-12-19  166.679993  167.600006  167.330002  167.059998  166.710007\n",
       "2016-12-20  167.600006  167.330002  167.059998  166.710007  167.139999\n",
       "2016-12-21  167.330002  167.059998  166.710007  167.139999  166.190002\n",
       "2016-12-22  167.059998  166.710007  167.139999  166.190002  166.600006\n",
       "2016-12-23  166.710007  167.139999  166.190002  166.600006  165.990005"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>NDX</th>\n",
       "      <th>DJIA</th>\n",
       "      <th>SP500</th>\n",
       "      <th>ewma_5</th>\n",
       "      <th>ewma_22</th>\n",
       "      <th>ewma_200</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Lower band</th>\n",
       "      <th>Upper band</th>\n",
       "      <th>Middle band</th>\n",
       "      <th>AO</th>\n",
       "      <th>AC</th>\n",
       "      <th>%R</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date.1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-16</th>\n",
       "      <td>168.970001</td>\n",
       "      <td>169.110001</td>\n",
       "      <td>166.059998</td>\n",
       "      <td>166.729996</td>\n",
       "      <td>7120600</td>\n",
       "      <td>165.422021</td>\n",
       "      <td>4914.859863</td>\n",
       "      <td>19843.410156</td>\n",
       "      <td>2258.070068</td>\n",
       "      <td>167.027881</td>\n",
       "      <td>163.427546</td>\n",
       "      <td>154.989750</td>\n",
       "      <td>2.586425</td>\n",
       "      <td>157.928373</td>\n",
       "      <td>169.568626</td>\n",
       "      <td>163.748500</td>\n",
       "      <td>7.344617</td>\n",
       "      <td>0.624629</td>\n",
       "      <td>30.372475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19</th>\n",
       "      <td>166.830002</td>\n",
       "      <td>167.259995</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.679993</td>\n",
       "      <td>2955900</td>\n",
       "      <td>165.372411</td>\n",
       "      <td>4934.850098</td>\n",
       "      <td>19883.060547</td>\n",
       "      <td>2262.530029</td>\n",
       "      <td>166.911918</td>\n",
       "      <td>163.710367</td>\n",
       "      <td>155.106071</td>\n",
       "      <td>2.498308</td>\n",
       "      <td>158.327848</td>\n",
       "      <td>169.798151</td>\n",
       "      <td>164.063000</td>\n",
       "      <td>7.099763</td>\n",
       "      <td>0.029005</td>\n",
       "      <td>30.403362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-20</th>\n",
       "      <td>167.490005</td>\n",
       "      <td>168.250000</td>\n",
       "      <td>166.449997</td>\n",
       "      <td>167.600006</td>\n",
       "      <td>2174600</td>\n",
       "      <td>166.285207</td>\n",
       "      <td>4953.799805</td>\n",
       "      <td>19974.619141</td>\n",
       "      <td>2270.760010</td>\n",
       "      <td>167.141281</td>\n",
       "      <td>164.048597</td>\n",
       "      <td>155.230389</td>\n",
       "      <td>2.474191</td>\n",
       "      <td>158.394491</td>\n",
       "      <td>170.214508</td>\n",
       "      <td>164.304500</td>\n",
       "      <td>6.579558</td>\n",
       "      <td>-0.521612</td>\n",
       "      <td>29.835067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-21</th>\n",
       "      <td>166.250000</td>\n",
       "      <td>167.940002</td>\n",
       "      <td>165.250000</td>\n",
       "      <td>167.330002</td>\n",
       "      <td>3575700</td>\n",
       "      <td>166.017321</td>\n",
       "      <td>4948.910156</td>\n",
       "      <td>19941.960938</td>\n",
       "      <td>2265.179932</td>\n",
       "      <td>167.204188</td>\n",
       "      <td>164.333936</td>\n",
       "      <td>155.350783</td>\n",
       "      <td>2.405561</td>\n",
       "      <td>158.532147</td>\n",
       "      <td>170.542852</td>\n",
       "      <td>164.537500</td>\n",
       "      <td>5.750294</td>\n",
       "      <td>-1.080446</td>\n",
       "      <td>30.001849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>167.360001</td>\n",
       "      <td>168.229996</td>\n",
       "      <td>166.580002</td>\n",
       "      <td>167.059998</td>\n",
       "      <td>2802600</td>\n",
       "      <td>165.749434</td>\n",
       "      <td>4934.390137</td>\n",
       "      <td>19918.880859</td>\n",
       "      <td>2260.959961</td>\n",
       "      <td>167.156125</td>\n",
       "      <td>164.570985</td>\n",
       "      <td>155.467293</td>\n",
       "      <td>2.302839</td>\n",
       "      <td>158.811937</td>\n",
       "      <td>170.771063</td>\n",
       "      <td>164.791500</td>\n",
       "      <td>5.037853</td>\n",
       "      <td>-1.324565</td>\n",
       "      <td>30.168631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>167.000000</td>\n",
       "      <td>167.490005</td>\n",
       "      <td>166.449997</td>\n",
       "      <td>166.710007</td>\n",
       "      <td>1701200</td>\n",
       "      <td>165.402189</td>\n",
       "      <td>4940.020020</td>\n",
       "      <td>19933.810547</td>\n",
       "      <td>2263.790039</td>\n",
       "      <td>167.007419</td>\n",
       "      <td>164.756987</td>\n",
       "      <td>155.579160</td>\n",
       "      <td>2.168195</td>\n",
       "      <td>158.984878</td>\n",
       "      <td>170.955123</td>\n",
       "      <td>164.970000</td>\n",
       "      <td>4.496765</td>\n",
       "      <td>-1.296082</td>\n",
       "      <td>30.384822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>166.979996</td>\n",
       "      <td>167.979996</td>\n",
       "      <td>166.850006</td>\n",
       "      <td>167.139999</td>\n",
       "      <td>1397500</td>\n",
       "      <td>165.828809</td>\n",
       "      <td>4965.810059</td>\n",
       "      <td>19945.039062</td>\n",
       "      <td>2268.879883</td>\n",
       "      <td>167.051612</td>\n",
       "      <td>164.964205</td>\n",
       "      <td>155.694194</td>\n",
       "      <td>2.072298</td>\n",
       "      <td>159.043100</td>\n",
       "      <td>171.158900</td>\n",
       "      <td>165.101000</td>\n",
       "      <td>4.287883</td>\n",
       "      <td>-0.942588</td>\n",
       "      <td>30.119214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>167.289993</td>\n",
       "      <td>167.740005</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.190002</td>\n",
       "      <td>1757500</td>\n",
       "      <td>164.886264</td>\n",
       "      <td>4926.290039</td>\n",
       "      <td>19833.679688</td>\n",
       "      <td>2249.919922</td>\n",
       "      <td>166.764409</td>\n",
       "      <td>165.070796</td>\n",
       "      <td>155.798629</td>\n",
       "      <td>1.897766</td>\n",
       "      <td>159.204593</td>\n",
       "      <td>171.263408</td>\n",
       "      <td>165.234000</td>\n",
       "      <td>3.827913</td>\n",
       "      <td>-0.852229</td>\n",
       "      <td>30.706031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>166.020004</td>\n",
       "      <td>166.990005</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.600006</td>\n",
       "      <td>1663500</td>\n",
       "      <td>165.293051</td>\n",
       "      <td>4918.279785</td>\n",
       "      <td>19819.779297</td>\n",
       "      <td>2249.260010</td>\n",
       "      <td>166.709608</td>\n",
       "      <td>165.203771</td>\n",
       "      <td>155.906106</td>\n",
       "      <td>1.772104</td>\n",
       "      <td>159.568089</td>\n",
       "      <td>171.337912</td>\n",
       "      <td>165.453001</td>\n",
       "      <td>3.419237</td>\n",
       "      <td>-0.794693</td>\n",
       "      <td>30.452770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>166.440002</td>\n",
       "      <td>166.699997</td>\n",
       "      <td>165.500000</td>\n",
       "      <td>165.990005</td>\n",
       "      <td>2952800</td>\n",
       "      <td>164.687836</td>\n",
       "      <td>4863.620117</td>\n",
       "      <td>19762.599609</td>\n",
       "      <td>2238.830078</td>\n",
       "      <td>166.469740</td>\n",
       "      <td>165.272139</td>\n",
       "      <td>156.006443</td>\n",
       "      <td>1.604795</td>\n",
       "      <td>160.506784</td>\n",
       "      <td>171.016217</td>\n",
       "      <td>165.761501</td>\n",
       "      <td>2.960442</td>\n",
       "      <td>-0.838005</td>\n",
       "      <td>30.829570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Volume  \\\n",
       "Date.1                                                                \n",
       "2016-12-16  168.970001  169.110001  166.059998  166.729996  7120600   \n",
       "2016-12-19  166.830002  167.259995  166.000000  166.679993  2955900   \n",
       "2016-12-20  167.490005  168.250000  166.449997  167.600006  2174600   \n",
       "2016-12-21  166.250000  167.940002  165.250000  167.330002  3575700   \n",
       "2016-12-22  167.360001  168.229996  166.580002  167.059998  2802600   \n",
       "2016-12-23  167.000000  167.490005  166.449997  166.710007  1701200   \n",
       "2016-12-27  166.979996  167.979996  166.850006  167.139999  1397500   \n",
       "2016-12-28  167.289993  167.740005  166.000000  166.190002  1757500   \n",
       "2016-12-29  166.020004  166.990005  166.000000  166.600006  1663500   \n",
       "2016-12-30  166.440002  166.699997  165.500000  165.990005  2952800   \n",
       "\n",
       "             Adj Close          NDX          DJIA        SP500      ewma_5  \\\n",
       "Date.1                                                                       \n",
       "2016-12-16  165.422021  4914.859863  19843.410156  2258.070068  167.027881   \n",
       "2016-12-19  165.372411  4934.850098  19883.060547  2262.530029  166.911918   \n",
       "2016-12-20  166.285207  4953.799805  19974.619141  2270.760010  167.141281   \n",
       "2016-12-21  166.017321  4948.910156  19941.960938  2265.179932  167.204188   \n",
       "2016-12-22  165.749434  4934.390137  19918.880859  2260.959961  167.156125   \n",
       "2016-12-23  165.402189  4940.020020  19933.810547  2263.790039  167.007419   \n",
       "2016-12-27  165.828809  4965.810059  19945.039062  2268.879883  167.051612   \n",
       "2016-12-28  164.886264  4926.290039  19833.679688  2249.919922  166.764409   \n",
       "2016-12-29  165.293051  4918.279785  19819.779297  2249.260010  166.709608   \n",
       "2016-12-30  164.687836  4863.620117  19762.599609  2238.830078  166.469740   \n",
       "\n",
       "               ewma_22    ewma_200      MACD  Lower band  Upper band  \\\n",
       "Date.1                                                                 \n",
       "2016-12-16  163.427546  154.989750  2.586425  157.928373  169.568626   \n",
       "2016-12-19  163.710367  155.106071  2.498308  158.327848  169.798151   \n",
       "2016-12-20  164.048597  155.230389  2.474191  158.394491  170.214508   \n",
       "2016-12-21  164.333936  155.350783  2.405561  158.532147  170.542852   \n",
       "2016-12-22  164.570985  155.467293  2.302839  158.811937  170.771063   \n",
       "2016-12-23  164.756987  155.579160  2.168195  158.984878  170.955123   \n",
       "2016-12-27  164.964205  155.694194  2.072298  159.043100  171.158900   \n",
       "2016-12-28  165.070796  155.798629  1.897766  159.204593  171.263408   \n",
       "2016-12-29  165.203771  155.906106  1.772104  159.568089  171.337912   \n",
       "2016-12-30  165.272139  156.006443  1.604795  160.506784  171.016217   \n",
       "\n",
       "            Middle band        AO        AC         %R  \n",
       "Date.1                                                  \n",
       "2016-12-16   163.748500  7.344617  0.624629  30.372475  \n",
       "2016-12-19   164.063000  7.099763  0.029005  30.403362  \n",
       "2016-12-20   164.304500  6.579558 -0.521612  29.835067  \n",
       "2016-12-21   164.537500  5.750294 -1.080446  30.001849  \n",
       "2016-12-22   164.791500  5.037853 -1.324565  30.168631  \n",
       "2016-12-23   164.970000  4.496765 -1.296082  30.384822  \n",
       "2016-12-27   165.101000  4.287883 -0.942588  30.119214  \n",
       "2016-12-28   165.234000  3.827913 -0.852229  30.706031  \n",
       "2016-12-29   165.453001  3.419237 -0.794693  30.452770  \n",
       "2016-12-30   165.761501  2.960442 -0.838005  30.829570  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4206, 5)\n",
      "(4206, 30, 19)\n"
     ]
    }
   ],
   "source": [
    "def inter_polation_norm_0_1(x):\n",
    "    return (x-x.min())/(x.max() - x.min())\n",
    "def inter_polation_norm_1_1(x):\n",
    "    return (2*(x-x.min())/(x.max() - x.min()) - 1)\n",
    "def z_score_norm(x):\n",
    "    return (x - x.mean())/x.std()\n",
    "df_rnn = inter_polation_norm_1_1(df_rnn)\n",
    "df_target = inter_polation_norm_1_1(df_target)\n",
    "df_rnn = df_rnn[:df_target.shape[0],:,:]\n",
    "print (df_target.shape)\n",
    "print (df_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Train test split\n",
    "x_train, y_train = df_rnn[:3453], df_target.loc[:'2014-01-01'].as_matrix()\n",
    "x_test, y_test = df_rnn[3454:], df_target.loc['2014-01-01':].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## helper function creating layers\n",
    "\n",
    "def new_weights(shape, stddev):\n",
    "    ## Xavier intialization\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=stddev,dtype=tf.float32)\n",
    "    \n",
    "    return tf.Variable(initial)\n",
    "## Biases initialization\n",
    "def new_biases(length):\n",
    "    initial = tf.constant(value=0, shape=[length], dtype=tf.float32)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def new_layer(in_size, out_size):\n",
    "    stddev = np.sqrt(np.float(2)/(in_size + out_size))\n",
    "    weights = new_weights([in_size, out_size], stddev)\n",
    "    biases = new_biases(out_size)\n",
    "    return {'weights': weights, 'biases':biases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X: Tensor(\"Placeholder:0\", shape=(?, 30, 19), dtype=float32)\n",
      "Target Y: Tensor(\"Placeholder_1:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Placeholder variables to hold input data\n",
    "X = tf.placeholder(tf.float32, [None, temporal_windows, n_features]) # Input data\n",
    "Y = tf.placeholder(tf.float32, [None, horizons]) # Labels\n",
    "print (\"Input X: {}\".format(X))\n",
    "print (\"Target Y: {}\".format(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Layer: {'weights': <tf.Variable 'Variable:0' shape=(15, 5) dtype=float32_ref>, 'biases': <tf.Variable 'Variable_1:0' shape=(5,) dtype=float32_ref>}\n",
      "* single cell: <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x0000013AB2D22828>\n",
      "* outputs transpose: Tensor(\"rnn/transpose:0\", shape=(?, 30, 15), dtype=float32)\n",
      "* outputs: Tensor(\"transpose_1:0\", shape=(30, ?, 15), dtype=float32)\n",
      "* input_regression: Tensor(\"add:0\", shape=(?, 5), dtype=float32)\n",
      "* y_rnn_regression: Tensor(\"Tanh:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer = new_layer(hidden_size, horizons) # output layer, outmost layer of the network\n",
    "print ('* Layer: {0}'.format(layer))\n",
    "\n",
    "# hidden_1_layer = new_layer(hidden_size, 100) # Hidden layer 1, outmost layer of the network\n",
    "# print ('* Hidden Layer 1: {0}'.format(hidden_1_layer))\n",
    "\n",
    "# softmax_layer = new_layer(100, N_LABELS) # Softmax layer, outmost layer of the network\n",
    "# print ('* Hidden Layer 1: {0}'.format(softmax_layer))\n",
    "\n",
    "\n",
    "# 1 cell LSTM\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(hidden_size, state_is_tuple=True) # A single LSTM cell\n",
    "\n",
    "# # Multi LSTM cells\n",
    "# rnn_cells = tf.contrib.rnn.MultiRNNCell([cell] * n_layers)\n",
    "# print ('* rnn_cells: {0}'.format(rnn_cells))\n",
    "# outputs_T, states = tf.contrib.dynamic_rnn(rnn_cells, X_rnn, dtype=tf.float32)\n",
    "# print ('* output transpose: {0}'.format(outputs_T))\n",
    "\n",
    "# initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "print ('* single cell: {0}'.format(cell))\n",
    "## Single rnn cell\n",
    "\n",
    "outputs_T, states = tf.nn.dynamic_rnn(cell=cell, inputs=X, dtype=tf.float32)\n",
    "print ('* outputs transpose: {0}'.format(outputs_T))\n",
    "\n",
    "outputs = tf.transpose(outputs_T, [1,0,2])\n",
    "print ('* outputs: {0}'.format(outputs))\n",
    "\n",
    "# # Use output of last step as input for softmax layer\n",
    "# last_step = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)\n",
    "# print ('* last_step: {0}'.format(last_step))\n",
    "# input_softmax = tf.matmul(last_step, layer['weights']) + layer['biases']\n",
    "# print ('* input_softmax: {0}'.format(input_softmax))\n",
    "# y_rnn_softmax = tf.nn.softmax(input_softmax)\n",
    "# print ('* y_rnn_softmax: {0}'.format(y_rnn_softmax))\n",
    "\n",
    "\n",
    "## Use mean of output of all steps as input for softmax layer\n",
    "# mean_step = tf.reduce_mean(input_tensor=outputs, axis=0)\n",
    "# print ('* mean_step: {0}'.format(mean_step))\n",
    "\n",
    "# # Hidden layer 1:\n",
    "\n",
    "# hidden_1 = tf.nn.relu(tf.matmul(mean_step, hidden_1_layer['weights']) + hidden_1_layer['biases'])\n",
    "# print hidden_1\n",
    "# input_softmax = tf.matmul(hidden_1, softmax_layer['weights']) + softmax_layer['biases']\n",
    "\n",
    "input_regression = tf.matmul(outputs[-1], layer['weights']) + layer['biases']\n",
    "print ('* input_regression: {0}'.format(input_regression))\n",
    "y_rnn_regression = tf.nn.tanh(input_regression)\n",
    "print ('* y_rnn_regression: {0}'.format(y_rnn_regression))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "cost = tf.reduce_mean(tf.square(y_rnn_regression-Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(cost)\n",
    "## Making Prediction\n",
    "y_pred = y_rnn_regression\n",
    "y_true = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 30\n",
    "TRAINING_EPOCHS = 20000\n",
    "\n",
    "## Helper function for optimization\n",
    "def optimize(train_x, train_y, n_epochs, batch_size, session, saver, dir_path):\n",
    "    n_samples = train_x.shape[0]\n",
    "    n_iterations = np.int(np.floor(n_samples/batch_size))+1\n",
    "    start_time = time.time()\n",
    "    cost_history = np.empty(shape=[1],dtype=float)\n",
    "    print (\"Training.......\")\n",
    "    if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "    for epoch in np.arange(n_epochs+1):\n",
    "        for itr in np.arange(n_iterations):\n",
    "            start = (itr * batch_size) % (n_samples - batch_size)\n",
    "            batch_x, batch_y = train_x[start:start + batch_size], train_y[start:start + batch_size]\n",
    "            feed_dict_train = {X: batch_x, Y: batch_y}\n",
    "            _, c = session.run([optimizer, cost], feed_dict=feed_dict_train)\n",
    "            cost_history = np.append(cost_history,c)\n",
    "            \n",
    "        if(epoch % 1000 == 0):\n",
    "            print (\"-- Elapsed time -- Epoch -- Cost value -- \")\n",
    "            print (\"-- {:12.6f} -- {:5d} -- {:10.5f} -- \".format((time.time() - start_time), \n",
    "                                                                                    epoch, \n",
    "                                                                                    c, \n",
    "                                                                                    ))\n",
    "            print (\"-- Making prediction at {}th epoch\".format(epoch))\n",
    "            make_prediction(x_test, df_target.loc['2014-01-01':], sess, BATCH_SIZE)\n",
    "            plt.savefig('{0}{1}th_epoch'.format(dir_path, epoch), dpi=1000)\n",
    "        \n",
    "#             Draw weights of convolutional layer\n",
    "#             if(epoch % (n_epochs/2) == 0):\n",
    "#                 plot_conv_weights(session, conv_weights[0], 'conv_1', 1, epoch)\n",
    "#                 plot_conv_weights(session, conv_weights[1], 'conv_2', 1, epoch)\n",
    "#                 plot_conv_weights(session, conv_weights[2], 'conv_3', 1, epoch)\n",
    "                  \n",
    "#         Save model in folder rnn_model\n",
    "        \n",
    "#         saver.save(sess, 'rnn_model/new_cnn')\n",
    "        \n",
    "#         print running time and output cost value graph\n",
    "    print (\"---Total Running time: %s seconds ---\" % (time.time() - start_time))\n",
    "    print ('*'*50)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.clf()\n",
    "    plt.plot(cost_history)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## Helper function to print confusion matrix\n",
    "def make_prediction(test_x, test_y, session, batch_size):\n",
    "    print (\"Making prediction.......\")\n",
    "    start_time = time.time()\n",
    "    n_samples = test_x.shape[0]\n",
    "    n_iterations = np.int(np.floor(n_samples/batch_size))+1\n",
    "    pred = np.zeros((n_samples, test_y.shape[1]))\n",
    "    true = test_y.as_matrix()\n",
    "    for itr in np.arange(n_iterations):\n",
    "        start = (itr * batch_size) % (n_samples - batch_size)\n",
    "        batch_x = test_x[start:start + batch_size]\n",
    "        feed_dict_test = {X: batch_x}\n",
    "        pred[start:start + batch_size] = session.run(y_pred, feed_dict=feed_dict_test)\n",
    "    pred = reshape_target_array(pred, horizons)\n",
    "    print (pred.shape)\n",
    "    true = reshape_target_array(true, horizons)\n",
    "    print(true.shape)\n",
    "    rmse = math.sqrt(metrics.mean_squared_error(pred, true))\n",
    "    mae = metrics.mean_absolute_error(pred, true)\n",
    "    print (\"RMSE = {}\".format(rmse))\n",
    "    print (\"MAE = {}\".format(mae))\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.plot(range(pred.shape[0]), pred[:,0], color = 'r', label='Predicted Values')\n",
    "    ax.plot(range(pred.shape[0]), true[:,0], color = 'b', label='Acutal Values')\n",
    "    ax.legend(loc='upper right', shadow=False)\n",
    "#     plt.show()\n",
    "    print (\"---Running Time: {0} seconds ---\".format((time.time() - start_time)))\n",
    "    print ('*'*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.......\n",
      "-- Elapsed time -- Epoch -- Cost value -- \n",
      "--     0.691992 --     0 --    0.10933 -- \n",
      "-- Making prediction at 0th epoch\n",
      "Making prediction.......\n",
      "(756, 1)\n",
      "(756, 1)\n",
      "RMSE = 0.37702717784919465\n",
      "MAE = 0.3174727913821682\n",
      "---Running Time: 0.11057901382446289 seconds ---\n",
      "**************************************************\n",
      "-- Elapsed time -- Epoch -- Cost value -- \n",
      "--   639.360679 --  1000 --    0.02874 -- \n",
      "-- Making prediction at 1000th epoch\n",
      "Making prediction.......\n",
      "(756, 1)\n",
      "(756, 1)\n",
      "RMSE = 0.3292922938506078\n",
      "MAE = 0.2493084997460801\n",
      "---Running Time: 0.13059234619140625 seconds ---\n",
      "**************************************************\n",
      "-- Elapsed time -- Epoch -- Cost value -- \n",
      "--  1347.050380 --  2000 --    0.01471 -- \n",
      "-- Making prediction at 2000th epoch\n",
      "Making prediction.......\n",
      "(756, 1)\n",
      "(756, 1)\n",
      "RMSE = 0.32061002627813\n",
      "MAE = 0.23565985073335607\n",
      "---Running Time: 0.24067139625549316 seconds ---\n",
      "**************************************************\n",
      "-- Elapsed time -- Epoch -- Cost value -- \n",
      "--  2103.669761 --  3000 --    0.03119 -- \n",
      "-- Making prediction at 3000th epoch\n",
      "Making prediction.......\n",
      "(756, 1)\n",
      "(756, 1)\n",
      "RMSE = 0.3091215721957571\n",
      "MAE = 0.23592360871509066\n",
      "---Running Time: 0.1055750846862793 seconds ---\n",
      "**************************************************\n",
      "-- Elapsed time -- Epoch -- Cost value -- \n",
      "--  2908.594935 --  4000 --    0.00425 -- \n",
      "-- Making prediction at 4000th epoch\n",
      "Making prediction.......\n",
      "(756, 1)\n",
      "(756, 1)\n",
      "RMSE = 0.4415149326239675\n",
      "MAE = 0.38067312371684126\n",
      "---Running Time: 0.11358070373535156 seconds ---\n",
      "**************************************************\n",
      "-- Elapsed time -- Epoch -- Cost value -- \n",
      "--  3770.867732 --  5000 --    0.00846 -- \n",
      "-- Making prediction at 5000th epoch\n",
      "Making prediction.......\n",
      "(756, 1)\n",
      "(756, 1)\n",
      "RMSE = 0.506773938622453\n",
      "MAE = 0.4536696321225805\n",
      "---Running Time: 0.12408781051635742 seconds ---\n",
      "**************************************************\n",
      "-- Elapsed time -- Epoch -- Cost value -- \n",
      "--  4688.682706 --  6000 --    0.00391 -- \n",
      "-- Making prediction at 6000th epoch\n",
      "Making prediction.......\n",
      "(756, 1)\n",
      "(756, 1)\n",
      "RMSE = 0.5090146447463573\n",
      "MAE = 0.446842064644165\n",
      "---Running Time: 0.10707592964172363 seconds ---\n",
      "**************************************************\n",
      "-- Elapsed time -- Epoch -- Cost value -- \n",
      "--  5636.647602 --  7000 --    0.03021 -- \n",
      "-- Making prediction at 7000th epoch\n",
      "Making prediction.......\n",
      "(756, 1)\n",
      "(756, 1)\n",
      "RMSE = 0.5021112256638526\n",
      "MAE = 0.44373111469587573\n",
      "---Running Time: 0.10857701301574707 seconds ---\n",
      "**************************************************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-50efffbdb9be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAINING_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Making prediction on training set\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmake_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'2014-01-01'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-b6a73e763ccb>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(train_x, train_y, n_epochs, batch_size, session, saver, dir_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mfeed_dict_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mcost_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_history\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Khanh\\Anaconda3\\envs\\py35\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5001\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   5002\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5003\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d = './RNN_test_1/'\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    optimize(x_train, y_train, TRAINING_EPOCHS, BATCH_SIZE, sess, saver, d)\n",
    "    print (\"Making prediction on training set\")\n",
    "    make_prediction(x_train, df_target.loc[:'2014-01-01'], sess, BATCH_SIZE)\n",
    "    print (\"Making training prediction on test 1 set\")\n",
    "    make_prediction(x_test, df_target.loc['2014-01-01':], sess, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
